{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, dataloader\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow.keras import Input, Sequential, Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization, Activation, \\\n",
        "    Dropout, Layer\n",
        "from tensorflow.keras.optimizers import Adam, schedules, SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import initializers\n"
      ],
      "metadata": {
        "id": "_mQlKjFwVncA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNqDcJdTT6wd",
        "outputId": "2176cb24-4afc-4294-e631-209b3b32b3c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dirName = \"/content/drive/MyDrive/DeepLearning2Data/lfw2\"\n",
        "train_path = \"/content/drive/MyDrive/pairsDevTrain.txt\"\n",
        "test_path = \"/content/drive/MyDrive/pairsDevTrain.txt\""
      ],
      "metadata": {
        "id": "e_Gq7jwbVRZR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def open_file(path):\n",
        "  examples_true = []\n",
        "  examples_false = []\n",
        "  with open(path) as train_file:\n",
        "    for line in train_file:\n",
        "      curr_line = line.split(\"\\t\")\n",
        "      curr_line[-1] = curr_line[-1][:-1]\n",
        "      if len(curr_line) == 3:\n",
        "        examples_true.append(curr_line)\n",
        "      if len(curr_line)==4:\n",
        "        examples_false.append(curr_line)\n",
        "  return (examples_false , examples_true)\n"
      ],
      "metadata": {
        "id": "sFXGQkPyVuTf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_pairs(main_directory, data_set, true_examples=True):\n",
        "  images = [np.array([None for x in range(2)]) for _ in range(len(data_set))]\n",
        "  main_dir_str = main_directory+\"/\"\n",
        "  for idx, i in tqdm(enumerate(data_set)):\n",
        "\n",
        "    if true_examples:\n",
        "      zeros1=(4-len(i[1]))*\"0\"\n",
        "      zeros2=(4-len(i[2]))*\"0\"\n",
        "      main_string = main_dir_str + f\"{i[0]}/{i[0]}_\"\n",
        "      image1 = main_string + zeros1+i[1]+\".jpg\"\n",
        "      image2 = main_string + zeros2+i[2]+\".jpg\"\n",
        "    else:\n",
        "      zeros1=(4-len(i[1]))*\"0\"\n",
        "      zeros2=(4-len(i[3]))*\"0\"\n",
        "\n",
        "      image1 = main_dir_str+i[0]+f\"/{i[0]}_\"+zeros1+i[1]+\".jpg\"\n",
        "      image2 = main_dir_str+i[2]+f\"/{i[2]}_\"+zeros2+i[3]+\".jpg\"\n",
        "    \n",
        "    images[idx][0] = image1\n",
        "    images[idx][1] = image2\n",
        "  \n",
        "  # print(f\"Total time: {end - start}. Time in main functions: {total_main}\")\n",
        "  \n",
        "  return images"
      ],
      "metadata": {
        "id": "VEKtMKH_Zz6w"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_images_from_files(path):\n",
        "    \"\"\"\n",
        "    We open the image in the given path. The path must lead to a .jpg file.\n",
        "    We then resize it to 105x105 like in the paper (the dataset contains 250x250 images.)\n",
        "\n",
        "    \"\"\"\n",
        "    my_image = tf.io.read_file(path)\n",
        "    my_image = tf.image.decode_jpeg(my_image, channels=1)\n",
        "    my_image = tf.image.resize(my_image, (105, 105))\n",
        "    my_image = tf.cast(my_image/255, tf.float32)\n",
        "    my_image = tf.image.convert_image_dtype(my_image, tf.float32)\n",
        "    return my_image"
      ],
      "metadata": {
        "id": "rbKarf3BaiYW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pair_from_files(paths_tuple):\n",
        "  return get_images_from_files(paths_tuple[0]), get_images_from_files(paths_tuple[1])"
      ],
      "metadata": {
        "id": "IylZojQ_wqNB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_false, train_true = open_file(train_path)\n",
        "test_false, test_true = open_file(test_path)\n",
        "\n",
        "train_false = get_image_pairs(dirName, train_false, true_examples=False)\n",
        "test_false = get_image_pairs(dirName, test_false, true_examples=False)\n",
        "test_true = get_image_pairs(dirName, test_true, true_examples=True)\n",
        "train_true = get_image_pairs(dirName, train_true, true_examples=True)"
      ],
      "metadata": {
        "id": "i9vUzQ7hBhVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c7a60d-85cd-4c1d-e297-de86c637d8f4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1100it [00:00, 223187.62it/s]\n",
            "1100it [00:00, 287944.48it/s]\n",
            "1100it [00:00, 300902.26it/s]\n",
            "1100it [00:00, 209154.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and validation (maybe here it goes bad?)\n",
        "validation_size = 0.25\n",
        "X_train_same, X_val_same, y_train_same, y_val_same = train_test_split(np.array(train_true), np.ones(len(train_true)), test_size=validation_size, random_state=42)\n",
        "X_train_diff, X_val_diff, y_train_diff, y_val_diff = train_test_split(np.array(train_false), np.zeros(len(train_false)), test_size=validation_size, random_state=42)"
      ],
      "metadata": {
        "id": "UJoSgM-Nz4G5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine same and diff to create final training sets\n",
        "X_train, y_train = np.vstack((X_train_same, X_train_diff)), np.hstack((np.array(y_train_same), np.array(y_train_diff)))\n",
        "X_val, y_val = np.vstack((X_val_same, X_val_diff)), np.hstack(np.array(y_val_same))\n",
        "X_test, y_test = np.vstack((np.array(test_true), np.array(test_false))), np.hstack((np.ones(len(test_true)), np.zeros(len(test_false))))"
      ],
      "metadata": {
        "id": "Ot9Dw75oDY0I"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given images and their labels gets them from file.\n",
        "def get_dataset(pairs, labels):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(pairs)\n",
        "  labels = tf.data.Dataset.from_tensor_slices(labels)\n",
        "  dataset = tf.data.Dataset.zip((dataset.map(pair_from_files, num_parallel_calls=tf.data.experimental.AUTOTUNE), labels))\n",
        "  return dataset.repeat(1).shuffle(buffer_size=1024).batch(16)\n"
      ],
      "metadata": {
        "id": "-OPyN6x9eF4s"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_train = len(train_false) + len(train_true)\n",
        "total_test = len(test_false) + len(test_true)\n",
        "total_val = len(X_val_diff) + len(X_val_same)\n",
        "total = total_train + total_test\n",
        "print(f\"Total images in train {total_train - total_val}\")\n",
        "print(f\"Total images in test {total_test}\")\n",
        "print(f\"Total images in validation {total_val}\")\n",
        "print(f\"The number of similar or different pairs is equal in all sets. So {len(train_false) - len(X_val_same)} in the training set, {len(test_true)} in the test set, and {len(X_val_same)} in the validation set\")\n",
        "print(f\"Total number of images: {total}\")"
      ],
      "metadata": {
        "id": "NRRRYRiLGanI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae7a7b6-6f86-48a4-f069-a7cd8c8b08a3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in train 1650\n",
            "Total images in test 2200\n",
            "Total images in validation 550\n",
            "The number of similar or different pairs is equal in all sets. So 825 in the training set, 1100 in the test set, and 275 in the validation set\n",
            "Total number of images: 4400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building The model"
      ],
      "metadata": {
        "id": "0s-9Jfpv7uY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From the article:\n",
        "# Minibatch size: 128\n",
        "# Allowed diff lr for each layer. Decayed uniformly by 1%\n",
        "\n",
        "# Momentum starts at 0.5 in every layer, increasing until mu_j of that layer.\n",
        "# mµ_j ∈ [0, 1],\n",
        "\n",
        "# CNN Weight initializations: W ~ N(0, 0.01)\n",
        "# Dense Weight inits: W ~ N(0, 0.2)\n",
        "# Bias initializations: B ~ N(0.5, 0.01)\n",
        "\n",
        "# Regularization: L2 on each layer\n",
        "# Stopped when validation error did not decrease for 20 epochs.\n",
        "\n",
        "# Adds a pooling layer. Optional batch normalization and dropout for experiments\n",
        "def add_pooling(layer, batchnorm, dropout):\n",
        "    \n",
        "    if (batchnorm):\n",
        "      layer = BatchNormalization()(layer)\n",
        "    m1 = MaxPooling2D()(layer)\n",
        "    if (dropout):\n",
        "      m1 = Dropout(dropout)(m1)\n",
        "    \n",
        "    return m1\n",
        "    \n",
        "def conv_layers(batchnorm = False, dropout = False):\n",
        "    input = Input(shape=(105, 105, 1), name='input_image')\n",
        "\n",
        "    conv1 = Conv2D(64, (10,10), activation='relu', kernel_regularizer=l2(0.0001),\n",
        "                kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "                bias_initializer=initializers.RandomNormal(mean=0.5, stddev=0.01))(input)\n",
        "\n",
        "\n",
        "\n",
        "    pool1 = add_pooling(conv1, batchnorm=batchnorm, dropout=dropout)\n",
        "\n",
        "    conv2 = Conv2D(128, (7, 7), activation='relu', kernel_regularizer=l2(0.0001),\n",
        "              kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "              bias_initializer=initializers.RandomNormal(mean=0.5, stddev=0.01))(pool1)\n",
        "\n",
        "    pool2 = add_pooling(conv2, batchnorm=batchnorm, dropout=dropout)\n",
        "\n",
        "    conv3 = Conv2D(128, (4, 4), activation='relu', kernel_regularizer=l2(0.0001),\n",
        "              kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "              bias_initializer=initializers.RandomNormal(mean=0.5, stddev=0.01))(pool2)\n",
        "\n",
        "    pool3 = add_pooling(conv3, batchnorm=batchnorm, dropout=dropout)\n",
        "\n",
        "    conv4 = Conv2D(256, (4,4), activation='relu', kernel_regularizer=l2(0.0001),\n",
        "              kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "              bias_initializer=initializers.RandomNormal(mean=0.5, stddev=0.01))(pool3)\n",
        "    \n",
        "    if (batchnorm):\n",
        "      conv4 = BatchNormalization()(conv4)\n",
        "\n",
        "    flatten = Flatten()(conv4)\n",
        "    dense1 = Dense(2048, activation='sigmoid', kernel_regularizer=l2(0.0001))(flatten)\n",
        "\n",
        "    return Model(inputs=[input], outputs=[dense1], name=\"embedding\")"
      ],
      "metadata": {
        "id": "1nch0cxENdDq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The layer mentioned in the paper to compute the distance.\n",
        "class L1Layer(Layer):\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "       \n",
        "    \n",
        "    def call(self, embed1, embed2):\n",
        "        return tf.math.abs(embed1 - embed2)"
      ],
      "metadata": {
        "id": "ECbfzGxSNrhb"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the functions we built in order to make a full model\n",
        "def make_full_model(batchnorm = False, dropout=False):\n",
        "    \n",
        "    # The two inputs to the network\n",
        "    input_image = Input(name='Image_one', shape=(105, 105, 1))\n",
        "    validation_image = Input(name='Image_two', shape=(105, 105, 1))\n",
        "    \n",
        "    # Creating the Convolutional Layers\n",
        "    conv_model = conv_layers(batchnorm=batchnorm, dropout=dropout)\n",
        "\n",
        "    # Layers Getting distance between the two image embeddings\n",
        "    combination_layer = L1Layer()\n",
        "    distances = combination_layer(conv_model(input_image), \n",
        "                                  conv_model(validation_image))\n",
        "    \n",
        "    classifier = Dense(1, activation=\"sigmoid\")(distances)\n",
        "\n",
        "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='full_network')"
      ],
      "metadata": {
        "id": "4kyUGggv-kIN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "\n",
        "siamese_net = make_full_model(batchnorm = False, dropout = 0.1)\n",
        "siamese_net.summary()\n",
        "\n",
        "optimizer = Adam(learning_rate)\n",
        "\n",
        "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['binary_accuracy'])\n",
        "\n",
        "# early stopping definition\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode=\"min\", verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfyN_uimAf9l",
        "outputId": "e3ed20e3-b719-4cf6-c243-08d14fb1b16a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"full_network\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Image_one (InputLayer)         [(None, 105, 105, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " Image_two (InputLayer)         [(None, 105, 105, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " embedding (Functional)         (None, 2048)         20071232    ['Image_one[0][0]',              \n",
            "                                                                  'Image_two[0][0]']              \n",
            "                                                                                                  \n",
            " l1_layer_2 (L1Layer)           (None, 2048)         0           ['embedding[0][0]',              \n",
            "                                                                  'embedding[1][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            2049        ['l1_layer_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,073,281\n",
            "Trainable params: 20,073,281\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = get_dataset(X_train,y_train)\n",
        "validation = get_dataset(X_val , y_val)\n",
        "test = get_dataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "08HBh2j3MQ-F"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training of the model\n",
        "start = time.time() \n",
        "model_out = siamese_net.fit(x=train, epochs=100, validation_data= validation, callbacks=[callback])\n",
        "end = time.time()\n",
        "\n",
        "# prediction results- an array contains all the predictions probabilities.\n",
        "print('Predict results')\n",
        "pred = siamese_net.predict(test)\n",
        "\n",
        "# training time measurments. \n",
        "print('Model convergence time: {} s.'.format(end - start))\n",
        "\n",
        "# evaluation of the model's performances on the test set\n",
        "results_test = siamese_net.evaluate(test)\n",
        "print('\\nEvaluation results:')\n",
        "print(results_test)\n",
        "\n",
        "# evaluation of the performance on the validation set\n",
        "results_val = siamese_net.evaluate(validation)\n",
        "print('\\nEvaluation results:')\n",
        "print(results_val)"
      ],
      "metadata": {
        "id": "E5Bt4GCDCzFa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "fff4d619-47d1-458f-d341-fcbdbf88fcd7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-08303fcc465a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#training of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\n/content/drive/MyDrive/DeepLearning2Data/lfw2/Edward_Said/Edward_Said_0002.jpg; No such file or directory\n\t [[{{node ReadFile_1}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_5506]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_out.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(model_out.history['binary_accuracy'])\n",
        "plt.plot(model_out.history['val_binary_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(model_out.history['loss'])\n",
        "plt.plot(model_out.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QnPWNNw-C0pU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
